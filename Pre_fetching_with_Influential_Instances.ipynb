{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-fetching with Influential Instances.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhSDb0q6bNT"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hNHFaBj4wpD"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9CTpg9Z4n1E"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeBJuyQP4z_Q"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr75D9EA41U8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/PhD/data/random_sequences_small.txt', 'r') as rf:\n",
        "  print(rf.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLi4PgbH42ty"
      },
      "source": [
        "## Create pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRCY65OD42dZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d2f4be-e9fd-4b95-baf5-932dc50cfe21"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PhD/data/random_sequences_tiny.txt', sep=\";\", names=['first_file', 'second_file', 'third_file', 'fourth_file', 'fifth_file'])\n",
        "df = df.reset_index()\n",
        "df = df.drop(columns=['fifth_file']) \n",
        "df = df.rename(columns = {'index': 'first_file', 'first_file':'second_file', 'second_file':'third_file', 'third_file':'fourth_file', 'fourth_file':'fifth_file'}, inplace = False)\n",
        "\n",
        "# Replace categorical with numerical values\n",
        "df = df.replace(['IPS'], 1, regex=True)\n",
        "df = df.replace(['Laboratory Results'], 2, regex=True)\n",
        "df = df.replace(['Prescription'], 3, regex=True)\n",
        "df = df.replace(['Image Report'], 4, regex=True) \n",
        "df = df.replace(['Allergies'], 5, regex=True)\n",
        "df = df.replace(['Diagnostic Report'], 6, regex=True)\n",
        "df = df.replace(['Pathology History'], 7, regex=True)\n",
        "df = df.replace(['Vital Signs'], 8, regex=True)\n",
        "df = df.replace(['Medication Report'], 9, regex=True)\n",
        "\n",
        "df.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of     first_file  second_file  third_file  fourth_file  fifth_file\n",
              "0            3            3           1            2           5\n",
              "1            5            5           1            2           2\n",
              "2            3            1           3            1           1\n",
              "3            3            5           2            1           1\n",
              "4            3            7           5            1           2\n",
              "5            3            2           3            3           4\n",
              "6            2            3           3            5           1\n",
              "7            2            3           2            1           1\n",
              "8            2            2           5            6           2\n",
              "9            5            3           1            2           7\n",
              "10           1            1           1            1           2\n",
              "11           5            5           1            2           3\n",
              "12           1            1           1            3           4\n",
              "13           3            2           1            9           2\n",
              "14           6            3           7            3           2\n",
              "15           6            2           2            2           2\n",
              "16           4            1           1            1           2\n",
              "17           4            2           3            5           6\n",
              "18           1            2           1            3           1\n",
              "19           1            1           5            4           3\n",
              "20           4            1           3            1           5\n",
              "21           1            1           3            2           2\n",
              "22           2            2           5            2           2\n",
              "23           4            3           2            1           3\n",
              "24           5            2           2            2           1\n",
              "25           4            2           2            3           2\n",
              "26           3            2           3            1           1\n",
              "27           3            4           3            4           5\n",
              "28           3            1           1            5           3\n",
              "29           3            3           9            3           2\n",
              "30           2            3           1            2           2\n",
              "31           2            1           3            3           2\n",
              "32           5            1           2            2           1\n",
              "33           2            1           2            4           2\n",
              "34           1            1           2            4           5\n",
              "35           2            2           1            4           1\n",
              "36           1            5           7            5           1\n",
              "37           1            5           1            1           7\n",
              "38           3            3           4            1           3\n",
              "39           2            5           1            2           2\n",
              "40           2            2           1            7           1\n",
              "41           2            1           1            1           3\n",
              "42           1            1           2            4           2\n",
              "43           3            1           3            2           5\n",
              "44           5            3           4            3           2\n",
              "45           2            1           2            4           1\n",
              "46           4            4           2            5           3\n",
              "47           4            2           5            3           4\n",
              "48           2            2           1            3           1\n",
              "49           3            1           3            3           3>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJzOg7a35iRV"
      },
      "source": [
        "Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "N247YYpN5iB1",
        "outputId": "8aefec77-4bb3-479b-f87f-7d5ff97ef26e"
      },
      "source": [
        "plt.hist2d(df.iloc[0], df.iloc[1], 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE5bH8zO5WfH"
      },
      "source": [
        "# LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzzKHtmj6hZf"
      },
      "source": [
        "## Series to supervised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_adXtCM6L3T",
        "outputId": "c7c50a22-b096-457a-e93e-7ededbd763ca"
      },
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "  if isinstance(data, list):\n",
        "    n_vars = 1\n",
        "  else:\n",
        "    n_vars = data.shape[1]\n",
        "  if isinstance(data, pd.DataFrame):\n",
        "    pass\n",
        "  else:\n",
        "    data = pd.DataFrame(data)\n",
        "  cols, names = list(), list()\n",
        "  print(n_vars)\n",
        "  # input sequence (t-n, ... t-1)\n",
        "  for i in range(n_in, 0, -1):\n",
        "    print(i)\n",
        "    cols.append(data.shift(i))\n",
        "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\n",
        "  # forecast sequence (t, t+1, ... t+n)\n",
        "  for i in range(0, n_out):\n",
        "    cols.append(data.shift(-i))\n",
        "    if i == 0:\n",
        "      names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "    else:\n",
        "      names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\n",
        "  # put it all together\n",
        "  agg = pd.concat(cols, axis=1)\n",
        "  agg.columns = names\n",
        "  #cols_to_use = names[:len(names) - (n_out)]\n",
        "  #agg = agg[cols_to_use]\n",
        "  # drop rows with NaN values\n",
        "  if dropnan:\n",
        "    agg.dropna(inplace=True)\n",
        "  return agg\n",
        "\n",
        "\n",
        "new_df = series_to_supervised(df,n_in= 1, n_out=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dau36zYD6PxH",
        "outputId": "0f8aa625-d6c3-4264-d66b-3ed20a6a45ac"
      },
      "source": [
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var4(t-1)</th>\n",
              "      <th>var5(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>var2(t)</th>\n",
              "      <th>var3(t)</th>\n",
              "      <th>var4(t)</th>\n",
              "      <th>var5(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   var1(t-1)  var2(t-1)  var3(t-1)  ...  var3(t)  var4(t)  var5(t)\n",
              "1        3.0        3.0        1.0  ...        1        2        2\n",
              "2        5.0        5.0        1.0  ...        3        1        1\n",
              "3        3.0        1.0        3.0  ...        2        1        1\n",
              "4        3.0        5.0        2.0  ...        5        1        2\n",
              "5        3.0        7.0        5.0  ...        3        3        4\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmhe5jr_6LKA"
      },
      "source": [
        "## Min - Max scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBAjpnJx6rPX"
      },
      "source": [
        "def Min_max_scal(data):\n",
        "\tarray = data.values\n",
        "\tvalues_ = array.astype('float32')\n",
        "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\tscaled = scaler.fit_transform(values_)\n",
        "\treturn scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fyxzugPf6tRi",
        "outputId": "7890d4c9-d190-47ba-a865-44186d40d4a0"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "columns = new_df.columns\n",
        "scaled_np = Min_max_scal(new_df)\n",
        "scaled_df = pd.DataFrame(scaled_np, columns=[columns])\n",
        "\n",
        "scaled_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var4(t-1)</th>\n",
              "      <th>var5(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>var2(t)</th>\n",
              "      <th>var3(t)</th>\n",
              "      <th>var4(t)</th>\n",
              "      <th>var5(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   var1(t-1) var2(t-1) var3(t-1) var4(t-1)  ...   var2(t) var3(t) var4(t)   var5(t)\n",
              "0       -0.2 -0.333333     -1.00     -0.75  ...  0.333333   -1.00   -0.75 -0.666667\n",
              "1        0.6  0.333333     -1.00     -0.75  ... -1.000000   -0.50   -1.00 -1.000000\n",
              "2       -0.2 -1.000000     -0.50     -1.00  ...  0.333333   -0.75   -1.00 -1.000000\n",
              "3       -0.2  0.333333     -0.75     -1.00  ...  1.000000    0.00   -1.00 -0.666667\n",
              "4       -0.2  1.000000      0.00     -1.00  ... -0.666667   -0.50   -0.50  0.000000\n",
              "5       -0.2 -0.666667     -0.50     -0.50  ... -0.333333   -0.50    0.00 -1.000000\n",
              "6       -0.6 -0.333333     -0.50      0.00  ... -0.333333   -0.75   -1.00 -1.000000\n",
              "7       -0.6 -0.333333     -0.75     -1.00  ... -0.666667    0.00    0.25 -0.666667\n",
              "8       -0.6 -0.666667      0.00      0.25  ... -0.333333   -1.00   -0.75  1.000000\n",
              "9        0.6 -0.333333     -1.00     -0.75  ... -1.000000   -1.00   -1.00 -0.666667\n",
              "10      -1.0 -1.000000     -1.00     -1.00  ...  0.333333   -1.00   -0.75 -0.333333\n",
              "11       0.6  0.333333     -1.00     -0.75  ... -1.000000   -1.00   -0.50  0.000000\n",
              "12      -1.0 -1.000000     -1.00     -0.50  ... -0.666667   -1.00    1.00 -0.666667\n",
              "13      -0.2 -0.666667     -1.00      1.00  ... -0.333333    0.50   -0.50 -0.666667\n",
              "14       1.0 -0.333333      0.50     -0.50  ... -0.666667   -0.75   -0.75 -0.666667\n",
              "15       1.0 -0.666667     -0.75     -0.75  ... -1.000000   -1.00   -1.00 -0.666667\n",
              "16       0.2 -1.000000     -1.00     -1.00  ... -0.666667   -0.50    0.00  0.666667\n",
              "17       0.2 -0.666667     -0.50      0.00  ... -0.666667   -1.00   -0.50 -1.000000\n",
              "18      -1.0 -0.666667     -1.00     -0.50  ... -1.000000    0.00   -0.25 -0.333333\n",
              "19      -1.0 -1.000000      0.00     -0.25  ... -1.000000   -0.50   -1.00  0.333333\n",
              "20       0.2 -1.000000     -0.50     -1.00  ... -1.000000   -0.50   -0.75 -0.666667\n",
              "21      -1.0 -1.000000     -0.50     -0.75  ... -0.666667    0.00   -0.75 -0.666667\n",
              "22      -0.6 -0.666667      0.00     -0.75  ... -0.333333   -0.75   -1.00 -0.333333\n",
              "23       0.2 -0.333333     -0.75     -1.00  ... -0.666667   -0.75   -0.75 -1.000000\n",
              "24       0.6 -0.666667     -0.75     -0.75  ... -0.666667   -0.75   -0.50 -0.666667\n",
              "25       0.2 -0.666667     -0.75     -0.50  ... -0.666667   -0.50   -1.00 -1.000000\n",
              "26      -0.2 -0.666667     -0.50     -1.00  ...  0.000000   -0.50   -0.25  0.333333\n",
              "27      -0.2  0.000000     -0.50     -0.25  ... -1.000000   -1.00    0.00 -0.333333\n",
              "28      -0.2 -1.000000     -1.00      0.00  ... -0.333333    1.00   -0.50 -0.666667\n",
              "29      -0.2 -0.333333      1.00     -0.50  ... -0.333333   -1.00   -0.75 -0.666667\n",
              "30      -0.6 -0.333333     -1.00     -0.75  ... -1.000000   -0.50   -0.50 -0.666667\n",
              "31      -0.6 -1.000000     -0.50     -0.50  ... -1.000000   -0.75   -0.75 -1.000000\n",
              "32       0.6 -1.000000     -0.75     -0.75  ... -1.000000   -0.75   -0.25 -0.666667\n",
              "33      -0.6 -1.000000     -0.75     -0.25  ... -1.000000   -0.75   -0.25  0.333333\n",
              "34      -1.0 -1.000000     -0.75     -0.25  ... -0.666667   -1.00   -0.25 -1.000000\n",
              "35      -0.6 -0.666667     -1.00     -0.25  ...  0.333333    0.50    0.00 -1.000000\n",
              "36      -1.0  0.333333      0.50      0.00  ...  0.333333   -1.00   -1.00  1.000000\n",
              "37      -1.0  0.333333     -1.00     -1.00  ... -0.333333   -0.25   -1.00 -0.333333\n",
              "38      -0.2 -0.333333     -0.25     -1.00  ...  0.333333   -1.00   -0.75 -0.666667\n",
              "39      -0.6  0.333333     -1.00     -0.75  ... -0.666667   -1.00    0.50 -1.000000\n",
              "40      -0.6 -0.666667     -1.00      0.50  ... -1.000000   -1.00   -1.00 -0.333333\n",
              "41      -0.6 -1.000000     -1.00     -1.00  ... -1.000000   -0.75   -0.25 -0.666667\n",
              "42      -1.0 -1.000000     -0.75     -0.25  ... -1.000000   -0.50   -0.75  0.333333\n",
              "43      -0.2 -1.000000     -0.50     -0.75  ... -0.333333   -0.25   -0.50 -0.666667\n",
              "44       0.6 -0.333333     -0.25     -0.50  ... -1.000000   -0.75   -0.25 -1.000000\n",
              "45      -0.6 -1.000000     -0.75     -0.25  ...  0.000000   -0.75    0.00 -0.333333\n",
              "46       0.2  0.000000     -0.75      0.00  ... -0.666667    0.00   -0.50  0.000000\n",
              "47       0.2 -0.666667      0.00     -0.50  ... -0.666667   -1.00   -0.50 -1.000000\n",
              "48      -0.6 -0.666667     -1.00     -0.50  ... -1.000000   -0.50   -0.50 -0.333333\n",
              "\n",
              "[49 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUW4WG661MX"
      },
      "source": [
        "Train - Test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgJwS-_w64Du"
      },
      "source": [
        "def reshape_data_single_lag(reframed, train_percentage, test_percentage, valid_percentage):\n",
        "\t# split into train and test sets\n",
        "\tvalues = reframed.values\n",
        "\t# Sizes\n",
        "\ttrain_size = int(len(reframed) * train_percentage)\n",
        "\ttest_size = int(len(reframed) * test_percentage)\n",
        "\tvalid_size = int(len(reframed) * valid_percentage)\n",
        "\n",
        "\ttrain = values[:train_size]\n",
        "\ttest = values[train_size:train_size + test_size]\n",
        "\tval = values[train_size + test_size:]\n",
        "\n",
        "\t# split into input and outputs\n",
        "\ttrain_X, train_y = train[:, :-1], train[:, -1]\n",
        "\ttest_X, test_y = test[:, :-1], test[:, -1]\n",
        "\tval_X, val_y = val[:, :-1], val[:, -1]\n",
        "\t# print(train_X.shape)\n",
        "\n",
        "\t### this reshape below is we using it for univariate timeseries\n",
        "\t# reshape input to be 3D [samples, timesteps, features]\n",
        "\ttrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "\ttest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "\tval_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
        "\n",
        "\tprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape, val_X.shape, val_y.shape)\n",
        "\n",
        "\treturn train_X, train_y, test_X, test_y, val_X, val_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_LnxoNR665S",
        "outputId": "3cde015b-d8e4-4068-f8cb-58a54611fe4e"
      },
      "source": [
        "train_X, train_y, test_X, test_y, val_X, val_y = reshape_data_single_lag(scaled_df,  0.45, 0.35, 0.2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 1, 9) (22,) (17, 1, 9) (17,) (10, 1, 9) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aATdm8jO7BbT"
      },
      "source": [
        "## LSTM Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReK99rIz7AY-"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, MaxPooling3D, Flatten\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, Conv3D\n",
        "\n",
        "def LSTM_model(train_X, train_y, test_X, test_y):\n",
        "    # design network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(90, return_sequences = True,  input_shape=(train_X.shape[1], train_X.shape[2])))  # 1 , 2\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(LSTM(70, return_sequences = True,  input_shape=(train_X.shape[1], train_X.shape[2])))  # 1 , 2\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(LSTM(50, return_sequences = True,  input_shape=(train_X.shape[1], train_X.shape[2])))  # 1 , 2\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(LSTM(30, return_sequences = True,  input_shape=(train_X.shape[1], train_X.shape[2])))  # 1 , 2\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(LSTM(30, return_sequences = True,  input_shape=(train_X.shape[1], train_X.shape[2])))  # 1 , 2\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(LSTM(15, return_sequences = False ))\n",
        "    model.add(Dropout(0.5))\n",
        "    #model.add(LSTM(30, return_sequences = False ))\n",
        "    #model.add(Dropout(0.2))\n",
        "    #model.add(LSTM(15, return_sequences = False ))\n",
        "    #model.add(Dense(50))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    # fit network\n",
        "    model.fit(train_X, train_y, epochs=10, batch_size=8, validation_data=(test_X, test_y),verbose=2, shuffle=False)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAz_qpLI7F14",
        "outputId": "31b2ab22-7a6a-402a-8426-4db8a47cd261"
      },
      "source": [
        "model = LSTM_model(train_X, train_y, test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 - 12s - loss: 0.5087 - val_loss: 0.5362\n",
            "Epoch 2/10\n",
            "3/3 - 0s - loss: 0.5032 - val_loss: 0.5303\n",
            "Epoch 3/10\n",
            "3/3 - 0s - loss: 0.4985 - val_loss: 0.5244\n",
            "Epoch 4/10\n",
            "3/3 - 0s - loss: 0.4908 - val_loss: 0.5184\n",
            "Epoch 5/10\n",
            "3/3 - 0s - loss: 0.4859 - val_loss: 0.5123\n",
            "Epoch 6/10\n",
            "3/3 - 0s - loss: 0.4810 - val_loss: 0.5063\n",
            "Epoch 7/10\n",
            "3/3 - 0s - loss: 0.4736 - val_loss: 0.5002\n",
            "Epoch 8/10\n",
            "3/3 - 0s - loss: 0.4700 - val_loss: 0.4941\n",
            "Epoch 9/10\n",
            "3/3 - 0s - loss: 0.4586 - val_loss: 0.4880\n",
            "Epoch 10/10\n",
            "3/3 - 0s - loss: 0.4591 - val_loss: 0.4818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyRZ7gH7P8H",
        "outputId": "485bb592-bcef-4658-bf6a-3cc842ebe72c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 90)             36000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 90)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1, 70)             45080     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 70)             0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1, 50)             24200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 50)             0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 1, 30)             9720      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 1, 30)             7320      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 30)             0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 15)                2760      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 125,096\n",
            "Trainable params: 125,096\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGvZi-lx7KJs"
      },
      "source": [
        "## Train - Test  loses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF_22qc37JlV"
      },
      "source": [
        "def plot_train_test_loss(model):\n",
        "    mpl.rcParams['figure.figsize'] = (12, 8)\n",
        "    mpl.rcParams['axes.grid'] = False\n",
        "    # plot history\n",
        "    plt.plot(model.history.history['loss'], label='train')\n",
        "    plt.plot(model.history.history['val_loss'], label='test')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "tF_ZxqRF7Rxj",
        "outputId": "b8d4c467-2428-405f-9e6b-f88a574d584a"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "plot_train_test_loss(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMm34EJw7UzD"
      },
      "source": [
        "## Predictions and scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaFVxmdI7W2V"
      },
      "source": [
        "def predictions_and_scores_for_LSTM(model, test_X,test_y):\n",
        "\t# make a prediction\n",
        "\tyhat = model.predict(test_X)\n",
        "\t# test_X_reshaped = test_X.reshape((test_X.shape[0], 3*2))\n",
        "\tyhat_reshaped = yhat.reshape((yhat.shape[0], yhat.shape[1]))\n",
        "\n",
        "\ttest_y_reshaped = test_y.reshape((len(test_y), 1))\n",
        "\n",
        "\t# calculate RMSE and R2_score\n",
        "\trmse = sqrt(mean_squared_error(test_y_reshaped, yhat_reshaped))\n",
        "\tr2score = r2_score(test_y_reshaped, yhat_reshaped)\n",
        "\t\n",
        "\tprint('Test RMSE: %.3f' % rmse)\n",
        "\tprint('R2_score: %f' % r2score)\n",
        "\treturn rmse, r2score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN2-xfiJ7ZCk",
        "outputId": "6f794409-af6a-4879-f389-9c2a7f558aef"
      },
      "source": [
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "predictions_and_scores_for_LSTM(model, test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 0.694\n",
            "R2_score: -0.594278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6941017582219153, -0.5942779327227838)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXEOn6_2Erwy"
      },
      "source": [
        "# Influential Instances using Deletion Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGP8RJSgJdOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4043697-ca8d-4cea-de02-d48fffee22d0"
      },
      "source": [
        "# The weights of the first model without deleting one or more \n",
        "initial_model_weights = model.get_weights()\n",
        "len(initial_model_weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NghmuQIE0HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69048155-00ce-4052-f89e-315534feb95c"
      },
      "source": [
        "model_weights = []\n",
        "rmse = []\n",
        "r2score = []\n",
        "\n",
        "for index, i in enumerate(train_X):\n",
        "  train_X_without_i = np.delete(train_X, index, 0)\n",
        "  train_y_without_i = np.delete(train_y, index, 0)\n",
        "  model_without_i = LSTM_model(train_X_without_i, train_y_without_i, test_X, test_y)\n",
        "  rmse_without_i, r2score_without_i = predictions_and_scores_for_LSTM(model_without_i, train_X_without_i, train_y_without_i)\n",
        "  model_weights += model_without_i.get_weights()\n",
        "  rmse.append(rmse_without_i)\n",
        "  r2score.append(r2score_without_i)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "3/3 - 0s - loss: 0.5108 - val_loss: 0.5199\n",
            "Epoch 5/10\n",
            "3/3 - 0s - loss: 0.5045 - val_loss: 0.5143\n",
            "Epoch 6/10\n",
            "3/3 - 0s - loss: 0.4999 - val_loss: 0.5086\n",
            "Epoch 7/10\n",
            "3/3 - 0s - loss: 0.4931 - val_loss: 0.5029\n",
            "Epoch 8/10\n",
            "3/3 - 0s - loss: 0.4855 - val_loss: 0.4971\n",
            "Epoch 9/10\n",
            "3/3 - 0s - loss: 0.4816 - val_loss: 0.4913\n",
            "Epoch 10/10\n",
            "3/3 - 0s - loss: 0.4782 - val_loss: 0.4855\n",
            "Test RMSE: 0.686\n",
            "R2_score: -0.733438\n",
            "Epoch 1/10\n",
            "3/3 - 12s - loss: 0.5124 - val_loss: 0.5363\n",
            "Epoch 2/10\n",
            "3/3 - 0s - loss: 0.5074 - val_loss: 0.5307\n",
            "Epoch 3/10\n",
            "3/3 - 0s - loss: 0.5020 - val_loss: 0.5252\n",
            "Epoch 4/10\n",
            "3/3 - 0s - loss: 0.4950 - val_loss: 0.5194\n",
            "Epoch 5/10\n",
            "3/3 - 0s - loss: 0.4905 - val_loss: 0.5136\n",
            "Epoch 6/10\n",
            "3/3 - 0s - loss: 0.4883 - val_loss: 0.5079\n",
            "Epoch 7/10\n",
            "3/3 - 0s - loss: 0.4775 - val_loss: 0.5021\n",
            "Epoch 8/10\n",
            "3/3 - 0s - loss: 0.4749 - val_loss: 0.4962\n",
            "Epoch 9/10\n",
            "3/3 - 0s - loss: 0.4709 - val_loss: 0.4904\n",
            "Epoch 10/10\n",
            "3/3 - 0s - loss: 0.4613 - val_loss: 0.4845\n",
            "Test RMSE: 0.678\n",
            "R2_score: -0.523404\n",
            "Epoch 1/10\n",
            "3/3 - 12s - loss: 0.5121 - val_loss: 0.5364\n",
            "Epoch 2/10\n",
            "3/3 - 0s - loss: 0.5062 - val_loss: 0.5306\n",
            "Epoch 3/10\n",
            "3/3 - 0s - loss: 0.4998 - val_loss: 0.5249\n",
            "Epoch 4/10\n",
            "3/3 - 0s - loss: 0.4961 - val_loss: 0.5192\n",
            "Epoch 5/10\n",
            "3/3 - 0s - loss: 0.4908 - val_loss: 0.5135\n",
            "Epoch 6/10\n",
            "3/3 - 0s - loss: 0.4858 - val_loss: 0.5079\n",
            "Epoch 7/10\n",
            "3/3 - 0s - loss: 0.4780 - val_loss: 0.5021\n",
            "Epoch 8/10\n",
            "3/3 - 0s - loss: 0.4731 - val_loss: 0.4963\n",
            "Epoch 9/10\n",
            "3/3 - 0s - loss: 0.4663 - val_loss: 0.4904\n",
            "Epoch 10/10\n",
            "3/3 - 0s - loss: 0.4579 - val_loss: 0.4844\n",
            "Test RMSE: 0.677\n",
            "R2_score: -0.522871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMzNvgx8TC-j",
        "outputId": "78c9a576-bffd-4978-d505-311e523861e6"
      },
      "source": [
        "len(model_without_i.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJruEosQjRG",
        "outputId": "a551590e-ec5d-4c7b-f03a-db66dca00439"
      },
      "source": [
        "len(model_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09-SZCEVFJe5"
      },
      "source": [
        "## Identification of most Influential instances with the use of DFBETA\n",
        "\n",
        "$DFBETA = β - β^{(-i)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usFiZyRbL3mP",
        "outputId": "130f6c1d-24f2-492d-e6c3-42aab5763013"
      },
      "source": [
        "initial_model_weights[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 360)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbHEoNDKYz3o",
        "outputId": "4fb9c2aa-fe79-4a23-eb30-83e5a05c45b0"
      },
      "source": [
        "model_weights[20].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 360)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWfsXN1xORaF",
        "outputId": "6dc5cef4-398c-4a3c-8f4e-6e042a217d8b"
      },
      "source": [
        "print(len(initial_model_weights))\n",
        "print(len(model_weights))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXY_cc0TfJK"
      },
      "source": [
        "for index, i in enumerate(model_weights):\n",
        "  # print(i)\n",
        "  print(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chB8tDXOHyIE"
      },
      "source": [
        "## DFBETA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mzlmLg9FNtt"
      },
      "source": [
        "total_weights = int(len(model_weights)/len(initial_model_weights))\n",
        "count=0\n",
        "# print(len(model_weights))\n",
        "# print(len(initial_model_weights))\n",
        "\n",
        "# for i in range(0, 2):\n",
        "count = 0\n",
        "dfbeta_all = []\n",
        "dfbeta_sum = []\n",
        "for i in range(0, len(model_weights)):\n",
        "  dfbeta = np.subtract(initial_model_weights[i-count], model_weights[i])\n",
        "  dfbeta_all.append(dfbeta)\n",
        "  if (i % len(initial_model_weights)==0):\n",
        "    count+=len(initial_model_weights)\n",
        "    dfbeta_sum.append(np.sum(dfbeta))\n",
        "\n",
        "dfbeta_sum_abs = np.abs(dfbeta_sum)\n",
        "dfbeta_sum = np.array(dfbeta_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQqaKEXVRi9s"
      },
      "source": [
        "dfbeta_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAEXV2jwO0NJ"
      },
      "source": [
        "dfbeta_sum_abs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuavY9_inBWm"
      },
      "source": [
        "most_influential_instances_indices = []\n",
        "number_of_influential_instances = len(dfbeta_sum)\n",
        "for i in range(0, number_of_influential_instances):\n",
        "  most_influential_instances_indices.append(np.argmax(dfbeta_sum))\n",
        "  dfbeta_sum[np.argmax(dfbeta_sum)] = -1000\n",
        "\n",
        "most_influential_instances_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1-vhXs0psPr"
      },
      "source": [
        "dfbeta_sum_abs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGixhFvcrW3D",
        "outputId": "429f77da-bab2-439f-cd84-f381fdfe4ab6"
      },
      "source": [
        "influential_instances = []\n",
        "for i in range(0, len(most_influential_instances_indices)):\n",
        "  influential_instances.append(df.loc[i].values.tolist())\n",
        "\n",
        "influential_instances"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 3, 1, 2, 5],\n",
              " [5, 5, 1, 2, 2],\n",
              " [3, 1, 3, 1, 1],\n",
              " [3, 5, 2, 1, 1],\n",
              " [3, 7, 5, 1, 2],\n",
              " [3, 2, 3, 3, 4],\n",
              " [2, 3, 3, 5, 1],\n",
              " [2, 3, 2, 1, 1],\n",
              " [2, 2, 5, 6, 2],\n",
              " [5, 3, 1, 2, 7],\n",
              " [1, 1, 1, 1, 2],\n",
              " [5, 5, 1, 2, 3],\n",
              " [1, 1, 1, 3, 4],\n",
              " [3, 2, 1, 9, 2],\n",
              " [6, 3, 7, 3, 2],\n",
              " [6, 2, 2, 2, 2],\n",
              " [4, 1, 1, 1, 2],\n",
              " [4, 2, 3, 5, 6],\n",
              " [1, 2, 1, 3, 1],\n",
              " [1, 1, 5, 4, 3],\n",
              " [4, 1, 3, 1, 5],\n",
              " [1, 1, 3, 2, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdagTp6VH26u"
      },
      "source": [
        "## Root Mean Square Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDT2qKXnH5ln",
        "outputId": "55f2beeb-c064-43d5-a1cb-87193d0bdf38"
      },
      "source": [
        "rmse_np = np.array(rmse)\n",
        "least_rmse_indices = []\n",
        "for i in range(0, len(rmse)):\n",
        "  least_rmse_indices.append(np.argmin(rmse_np))\n",
        "  rmse_np[np.argmin(rmse_np)] = 99999\n",
        "\n",
        "least_rmse_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 2, 5, 6, 1, 17, 16, 0, 13, 15, 14, 21, 20, 3, 9, 7, 12, 10, 19, 18, 4, 11]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEu93uxkMDtU"
      },
      "source": [
        "#$R^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQNpYXvyMHPB",
        "outputId": "3100a5ce-d398-4165-b920-c33da8ecd4b6"
      },
      "source": [
        "r2score_np = np.array(r2score)\n",
        "highest_r2score_indices = []\n",
        "for i in range(0, len(r2score)):\n",
        "  highest_r2score_indices.append(np.argmax(r2score_np))\n",
        "  r2score_np[np.argmax(r2score_np)] = -100\n",
        "\n",
        "highest_r2score_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 5, 6, 1, 0, 13, 15, 14, 21, 20, 3, 9, 7, 17, 10, 12, 18, 4, 11, 19, 16, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2o94YdASYs7"
      },
      "source": [
        "## DFBETA, RMSE, $R^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTnsnp_PSeNY",
        "outputId": "23b43df6-b5d3-4d3b-dd6a-42650158f872"
      },
      "source": [
        "metrics = np.column_stack([most_influential_instances_indices, least_rmse_indices, highest_r2score_indices])\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  8,  2],\n",
              "       [ 8,  2,  5],\n",
              "       [12,  5,  6],\n",
              "       [20,  6,  1],\n",
              "       [11,  1,  0],\n",
              "       [16, 17, 13],\n",
              "       [13, 16, 15],\n",
              "       [ 4,  0, 14],\n",
              "       [ 1, 13, 21],\n",
              "       [21, 15, 20],\n",
              "       [ 5, 14,  3],\n",
              "       [ 2, 21,  9],\n",
              "       [ 3, 20,  7],\n",
              "       [10,  3, 17],\n",
              "       [ 6,  9, 10],\n",
              "       [15,  7, 12],\n",
              "       [18, 12, 18],\n",
              "       [ 9, 10,  4],\n",
              "       [14, 19, 11],\n",
              "       [ 0, 18, 19],\n",
              "       [19,  4, 16],\n",
              "       [17, 11,  8]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v0Hh9SDE3js"
      },
      "source": [
        "# K-Means using Dynamic Time Warping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt0Nd4mxElz_",
        "outputId": "215472f9-4dba-427c-f75e-e129e9f1eb49"
      },
      "source": [
        "!python -m pip install tslearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tslearn\n",
            "  Downloading tslearn-0.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (793 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 92 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 440 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 450 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 460 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 471 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 481 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 491 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 501 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 512 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 522 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 532 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 542 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 552 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 563 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 573 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 583 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 593 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 604 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 614 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 624 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 634 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 645 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 655 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 665 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 675 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 686 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 696 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 706 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 716 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 727 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 737 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 747 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 757 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 768 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 778 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 788 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 793 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.0.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.29.24)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from tslearn) (0.51.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tslearn) (1.19.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->tslearn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->tslearn) (57.4.0)\n",
            "Installing collected packages: tslearn\n",
            "Successfully installed tslearn-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxSt9V7gFEo6",
        "outputId": "291482ef-f361-4162-b447-32502d5f9da7"
      },
      "source": [
        "from tslearn.metrics import dtw\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "\n",
        "kmeans_model = TimeSeriesKMeans(n_clusters=len(metrics), init=\"random\")\n",
        "\n",
        "kmeans_model.fit(influential_instances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TimeSeriesKMeans(dtw_inertia=False, init='random', max_iter=50,\n",
              "                 max_iter_barycenter=100, metric='euclidean',\n",
              "                 metric_params=None, n_clusters=22, n_init=1, n_jobs=None,\n",
              "                 random_state=None, tol=1e-06, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "eJeiAIv-XKkd",
        "outputId": "e970e86c-ac20-473c-8d86-ed0df2e7e0eb"
      },
      "source": [
        "plt.plot()\n",
        "# plt.show()\n",
        "# df.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-772542603150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpos_only\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 raise TypeError(\"{} got an unexpected keyword argument {!r}\"\n\u001b[0;32m--> 159\u001b[0;31m                                 .format(self.command, pos_only))\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: plot got an unexpected keyword argument 'x'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWCX9Qswt4YP",
        "outputId": "7348050e-0e0b-48f6-e9e8-ff8843e9da3a"
      },
      "source": [
        "res = kmeans_model.predict(df.loc[[49]].values.tolist())\n",
        "kmeans_model.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tslearn/utils/utils.py:89: UserWarning: 2-Dimensional data passed. Assuming these are 1 1-dimensional timeseries\n",
            "  '{} 1-dimensional timeseries'.format(X.shape[0]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[3.],\n",
              "        [7.],\n",
              "        [5.],\n",
              "        [1.],\n",
              "        [2.]],\n",
              "\n",
              "       [[1.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [3.],\n",
              "        [1.]],\n",
              "\n",
              "       [[3.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [5.]],\n",
              "\n",
              "       [[6.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[5.],\n",
              "        [5.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.]],\n",
              "\n",
              "       [[3.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [9.],\n",
              "        [2.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [3.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[5.],\n",
              "        [5.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [3.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[5.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [7.]],\n",
              "\n",
              "       [[3.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [9.],\n",
              "        [2.]],\n",
              "\n",
              "       [[3.],\n",
              "        [7.],\n",
              "        [5.],\n",
              "        [1.],\n",
              "        [2.]],\n",
              "\n",
              "       [[6.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[2.],\n",
              "        [3.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [1.]],\n",
              "\n",
              "       [[3.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [4.]],\n",
              "\n",
              "       [[5.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [7.]],\n",
              "\n",
              "       [[2.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [5.],\n",
              "        [1.]],\n",
              "\n",
              "       [[3.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [4.]],\n",
              "\n",
              "       [[5.],\n",
              "        [5.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.]],\n",
              "\n",
              "       [[2.],\n",
              "        [3.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [1.]],\n",
              "\n",
              "       [[2.],\n",
              "        [2.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [2.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [3.],\n",
              "        [2.],\n",
              "        [2.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw7bFtufVHXY"
      },
      "source": [
        "For each point (instance in the data set) we calcuate the Dynamic Time Warping for all cluster centers. If it less than a given distance it is considered a point in the cluster, otherwise it is considered an outlier and is dropped from the data set. The final data set is then used by the LSTM model for re-training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9vJME8cE7ko"
      },
      "source": [
        "# Re-train LSTM model based on K-Means outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBtcYR21Htdy"
      },
      "source": [
        "# Appendix - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWaYf_JyPJF0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "6153b97d-4fef-40d8-aa23-b35bc28f2e25"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('lstm.py','wb').write(src)\n",
        "# open('preprocessing.py', 'wb').write(src)\n",
        "\n",
        "from preprocessing import read_csv, series_to_supervised, Min_max_scal, reshape_data_single_lag\n",
        "from lstm import LSTM_model\n",
        "\n",
        "df = read_csv()\n",
        "new_df = series_to_supervised(df, n_in=1, n_out=1)\n",
        "new_df = new_df.astype(int)\n",
        "\n",
        "columns = new_df.columns\n",
        "scaled_np = Min_max_scal(new_df)\n",
        "scaled_df = pd.DataFrame(scaled_np, columns=[columns])\n",
        "\n",
        "train_X, train_y, test_X, test_y, val_X, val_y = reshape_data_single_lag(scaled_df,  0.45, 0.35, 0.2 )\n",
        "\n",
        "model = LSTM_model(train_X, train_y, test_X, test_y)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89838a3d-fbe5-4d04-b762-64282bcff59b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89838a3d-fbe5-4d04-b762-64282bcff59b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-435e428507ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# open('preprocessing.py', 'wb').write(src)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}